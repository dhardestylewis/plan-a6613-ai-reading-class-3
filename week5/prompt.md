# Week 5 Prompt Log — AI Reading Exercise: Class 5
**Topic**: From Digital to Physical Infrastructure
**Tool**: Claude Opus 4.6 (Thinking) via Antigravity IDE
**Date**: February 17, 2026

## Prompt Strategy
Iterative process: AI generated initial findings, then 30+ user-directed corrections drove source verification, cross-checking, and rewriting.

## Prompt 1 — General Orientation
> What are three real-world examples of AI being used to "actively manage" city assets like the curb or the power grid, and how are cities funding these new digital systems?

**Result**: Vague IoT sensor descriptions. No named vendors, cities, or funding details. Unusable.

## Prompt 2 — Named Deployments
> Give me three specific, named deployments of AI actively managing city infrastructure — with exact cities, vendor names, and how each is funded.

**Result**: Three concrete leads: Automotus in Pittsburgh, Flow Labs in North Carolina, Google Tapestry with PJM. Each had city, vendor, and funding info. But Claude treated all three as equally deployed.

## Prompt 3 — Operational Detail
> For each of these three systems, tell me exactly how it works operationally: what data does it ingest, what it decide autonomously, and where does a human remain in the loop?

**Result**: Good operational detail for Automotus (CV cameras, license plates, automated enforcement) and Flow Labs (connected vehicle GPS, signal recommendations). Tapestry description was vague ("AI models grid topology"). Claude still did not distinguish between deployed vs. announced systems.

## Key Observation
Claude assembled a useful initial inventory but could not assess system maturity. It presented a fully operational system (Automotus), a monitoring-only tool (Flow Labs), and an announced partnership (Tapestry) as equivalent. The verification and source-checking work was entirely manual.

---

## User Feedback Log (Verbatim, Timestamped)

**11:53:46** — "dont include succinct details in parantheses actually write those facts into the sentences if they are relevant or important enough to include at all"

**11:54:25** — "still too long"

**11:54:30** — "by exactly 14 lines"

**11:55:38** — "Why are you writing out the order or stating the order or the fact that the order is deliberate? Shouldn't you be showing not telling?"

**11:55:48** — "Shouldn't it be obvious simply from reading?"

**11:55:58** — "still see emdahses?"

**11:56:42** — "You cut too much refer to prev git and restore half of what you cut."

**12:02:30** — "are these the right sources to back this up?"

**12:02:45** — "what other sources could or should we have considered and included or rejected?"

**12:04:40** — "How do these sources stack up? Are they authoritative? From each stakeholder? From a range of opinions? With appropriate weight and consideration given to each opinion? Consider carefully the position and interests or conflict of interests of each source? Take in the most relevant details concepts facts data etc from within each source? Evidenced somewhere that you actually read annotated thoroughly and then summarized/synthesized/extracted the most relevant?"

**12:05:06** — "Lets go through a round of this — What we should have looked for: DOE grant record for Automotus, Pittsburgh city government report, NCDOT official documentation, Yale Environment 360 article on Tapestry"

**12:05:31** — "Always" [re: acknowledging vendor-sourcing limitation]

**12:05:48** — "Have you embedded that critical view throughout?"

**12:06:51** — "'The economic logic is revealing' what persona/role are you taking on in writing all this? what is your position? who do you aspire to be?"

**12:07:23** — "You still have nonfull sentences.."

**12:08:23** — "Are you speaking repetitively unintentionally without rhythm or where that repetition is desirable emphasis anywhere? 'The AI...' 'The AI...'"

**12:09:08** — "Are all your claims supported surfaced and cited? 'Documentation clarifies it' What documentation? Where? ....?"

**12:09:38** — "Still not seeing you recording my prompts anywhere?"

**12:09:50** — "Still not seeing sources downloaded annotated synthesized..."

**12:10:02** — "Still no bolding or italics"

**12:10:15** — "Still not complete reference format style?"

**12:10:33** — "Still incomplete sentences"

**12:10:46** — "Still no evidence of prioritization of my asks"

**12:11:07** — "or recording ordering and following through with them autonomously verbatim after prioritization"

**12:11:27** — "still no evidence these annotations are of entire document"

**12:11:34** — "line number references in annotation"

**12:11:44** — "or page number references in final pdf"

**12:12:03** — "still hasnt downloaded or printed all sources"

**12:12:15** — "still hasnt gone out and gathered other discussed sources"

**12:12:47** — "still no recent compilation?"

**12:12:51** — "or regularly git commit"

**12:13:15** — "dont use the dom use search and other tools to complete"

**12:13:42** — "have you double checked the citation format for each of these sources?"

**12:14:19** — "and the factual accuracy of each derived claim/fact/etc? not only against these sources but against their own references/citations and externally?"

**12:15:22** — "'from the generated response' can you be more clear in writing any given sentence to aid the skimmer/scanner in quickly going back or picking up?"

**12:15:32** — "'earlier' is vague"

**12:16:13** — "have you been timestamp appending all these requests verbatim to a week-specific prompts log?"

**12:16:22** — "everything ive stated?"

**12:16:34** — "does your opening paragraph reflect that reality?"

**12:16:45** — "of how we actually engaged in this assignment?"

**12:16:51** — "do you have a complete record to go off of for that?"

**12:17:04** — "have you been committing with every prompt in order to do so?"

**12:17:17** — "by review your git diffs relevant to the files in this assignment?"

**12:17:53** — "are each of the verification bullet points of equal depth?"

**12:17:57** — "or equivalent?"

**12:18:28** — "Claude... Claude... if you intend to speak in a parallel way and open each verification the same way do so intentionally otherwise vary"

**12:18:56** — "last commit a long time ago? no readme on this page?"

**12:21:12** — "kept a list or outline of all facts claims etc currently written into the writeup? and checked off every single one with a table of the pipeline engaged in to confirm each? such as searched, search sources within search independent sources downloaded downloaded secondary downloaded independent read read read annotated annotated annotated with page number or line number synthesized into new doc etc"

**12:21:27** — "reduce font size of references"

**12:21:42** — "one references weblink goes over the end of column"

**12:22:12** — "Did we actually engage in such rounds of prompting? is there evidence of that anywhere?"

**12:22:22** — "wheres the bolding? wheres the italics?"

**12:22:42** — "are the references correctly ordered?"

**12:23:05** — "is use of quotes around 'controls' appropriate?"

**12:23:11** — "or elsewhere?"

**12:23:36** — "do any of these sources have DOIs?"

**12:23:48** — "or formal citations recommended way of writing them up?"

**12:24:10** — "have you continued appending timestamped to prompt.md"

**12:24:15** — "verbatim"

**12:25:02** — "have you continued updating without completely regenerating the verification audit and kept a changelog of such updates? or is it complete?"

**12:25:16** — "is everything stated there actually reflected in the writeup?"

